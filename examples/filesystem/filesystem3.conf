application {
  name = Filesystem Example
  executor.instances = 1
}
steps {
  fix {
    input {
      type = filesystem
      // Be sure to load this file into HDFS first!
      path = "hdfs://nameservice1/tmp/data/fix-output"
//      path = "/tmp/data/example-input.json"
      format = csv
      translator {
        type = delimited
        delimiter = ","
        schema {
          type = flat
          field.names = [clordid, symbol, orderqty, leavesqty, cumqty, avgpx, transacttime]
          field.types = [string,long,string,int,int,int,int]
        }
      }
    }
  }
  orderhistory {
    dependencies = [fix]
    deriver {
      type = sql
      query.literal = """
SELECT _c0 AS clordid, _c1 AS symbol, _c2 AS orderqty, _c3 AS leavesqty, _c4 AS cumqty,
 _c6 AS transacttime FROM fix"""
    }
    planner {
      type = upsert
    }
    output {
      type = hbase
      table.name = "envelopetest2:test"
      mapping {
        rowkey.columns = ["symbol","transacttime"]
        columns {
          symbol {
            cf = "rowkey"
            col = "symbol"
            type = "string"
          }
          transacttime {
            cf = "rowkey"
            col = "transacttime"
            type = "long"
          }
          clordid {
            cf = "cf1"
            col = "clordid"
            type = "string"
          }
          orderqty {
            cf = "cf2"
            col = "orderqty"
            type = "int"
          }
          leavesqty {
            cf = "cf2"
            col = "leavesqty"
            type = "int"
          }
          cumqty {
            cf = "cf2"
            col = "cumqty"
            type = "int"
          }
        }
      }
    }
  }
}
